{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f32a9c-409e-4b41-b19c-8cc74a773d2a",
   "metadata": {},
   "source": [
    "###### Name: Mysara Qistina binti Mahadzir\n",
    "###### Student ID: SW01083524"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10714737-a36e-4ef0-99e8-c48903010fde",
   "metadata": {},
   "source": [
    "##### The chosen e-commerce platform is Shopee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f42dd1-52df-47d1-9162-75931168355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import pickle\n",
    "import time\n",
    "import bs4\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a924f4e-fbec-45ee-b824-c9f99f08432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as 'extracted_review.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Start undetected Chrome with custom options\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(r\"C:\\Users\\user\\AppData\\Local\\Google\\Chrome\\User Data\")  # Path to Chrome User Data\n",
    "options.add_argument(\"--profile-directory=Default\")  # Use the default profile\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Disable automation detection\n",
    "options.add_argument(\"--start-maximized\")  # Start with a maximized window\n",
    "\n",
    "# Initialize the Chrome driver with options\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# Open Shopee product page and wait for login\n",
    "url = \"https://shopee.com.my/Apple-MacBook-Air-(13-inch-M1)-i.1278832578.28854289815\"\n",
    "driver.get(url)\n",
    "time.sleep(60)  # Wait for user to login manually\n",
    "\n",
    "# Scroll to load reviews on the product page\n",
    "driver.execute_script(\"window.scrollBy(0, 700);\")  # Scroll the page down\n",
    "time.sleep(5)  # Wait for page to load more reviews\n",
    "\n",
    "# Initialize list to store reviews data\n",
    "reviews = []\n",
    "\n",
    "# Loop through multiple pages of reviews\n",
    "for k in range(5):  # Scrape reviews from 5 pages\n",
    "    time.sleep(3)  # Wait for content to load\n",
    "    soup = bs4.BeautifulSoup(driver.page_source, \"html.parser\")  # Parse page source using BeautifulSoup\n",
    "\n",
    "    # Extract review details (name, date, and content) for each review\n",
    "    for r in soup.find_all(\"div\", class_=\"shopee-product-rating\"):\n",
    "        name = r.find(\"a\", class_=\"shopee-product-rating__author-name\")  # Find reviewer name\n",
    "        date = r.find(\"div\", class_=\"shopee-product-rating__time\")  # Find review date\n",
    "        content = r.find(\"div\", style=\"margin-top: 0.75rem;\")  # Find review content\n",
    "\n",
    "        # Clean the review date\n",
    "        if date:\n",
    "            full_text = date.text.strip()\n",
    "            clean_date = full_text.split(\" | \")[0]  # Extract date before separator\n",
    "        else:\n",
    "            clean_date = \"No Date\"  # If no date available, set as 'No Date'\n",
    "        \n",
    "        # Append review data (name, date, content) to the reviews list\n",
    "        reviews.append([\n",
    "            name.text.strip() if name else \"No Name\",  # If name exists, strip whitespace\n",
    "            clean_date,  # Cleaned review date\n",
    "            content.text.strip() if content else \"No Content\"  # If content exists, strip whitespace\n",
    "        ])\n",
    "\n",
    "    # Try to click the next page button to load more reviews\n",
    "    try:\n",
    "        next_btn = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.shopee-icon-button--right\"))\n",
    "        )\n",
    "        next_btn.click()  # Click the next page button\n",
    "    except:\n",
    "        print(\"No more pages.\")  # If no next page is available, exit the loop\n",
    "        break\n",
    "\n",
    "# Close the browser after scraping\n",
    "driver.quit()\n",
    "\n",
    "# Save scraped reviews to a CSV file\n",
    "df = pd.DataFrame(reviews, columns=[\"Reviewer Name\", \"Review Date\", \"Review Content\"])\n",
    "df.to_csv(\"extracted_review.csv\", index=False)\n",
    "\n",
    "# Print success message\n",
    "print(\"Data saved as 'extracted_review.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd60bc3-8d8b-42c3-af13-dcd7268695f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
